{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **Import library**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.compat.v1 import image\n","from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D, UpSampling2D, Conv2DTranspose, GlobalAveragePooling2D\n","from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, Lambda\n","from tensorflow.keras.layers import BatchNormalization, Activation, concatenate, multiply, add\n","from tensorflow.keras.layers import ReLU, LeakyReLU, PReLU, ELU, Softmax\n","from tensorflow.keras.activations import sigmoid\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.models import Model\n","from keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n","from keras.models import Model\n","from keras.applications.resnet import ResNet50\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import *\n","from tensorflow.python.keras.utils.data_utils import Sequence\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.optimizers import *\n","from tensorflow.keras import backend as keras\n","from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n","from tensorflow.keras import layers\n","import os\n","import numpy as np\n","import cv2\n","from glob import glob\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from IPython.display import clear_output\n","from tensorflow.keras.optimizers import Adam \n","from sklearn.model_selection import train_test_split\n","import shutil\n","import random\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{},"source":["# Define Model"]},{"cell_type":"markdown","metadata":{},"source":["**R2U-net**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T05:18:26.554315Z","iopub.status.busy":"2022-05-29T05:18:26.554062Z","iopub.status.idle":"2022-05-29T05:18:26.567926Z","shell.execute_reply":"2022-05-29T05:18:26.566464Z","shell.execute_reply.started":"2022-05-29T05:18:26.554288Z"},"trusted":true},"outputs":[],"source":["def decode_layer(X, channel, pool_size, unpool, kernel_size=3, \n","                 activation='ReLU', batch_norm=False, name='decode'):\n","    '''\n","    An overall decode layer, based on either upsampling or trans conv.\n","\n","    decode_layer(X, channel, pool_size, unpool, kernel_size=3,\n","                 activation='ReLU', batch_norm=False, name='decode')\n","\n","    Input\n","    ----------\n","        X: input tensor.\n","        pool_size: the decoding factor.\n","        channel: (for trans conv only) number of convolution filters.\n","        unpool: True or 'bilinear' for Upsampling2D with bilinear interpolation.\n","                'nearest' for Upsampling2D with nearest interpolation.\n","                False for Conv2DTranspose + batch norm + activation.           \n","        kernel_size: size of convolution kernels. \n","                     If kernel_size='auto', then it equals to the `pool_size`.\n","        activation: one of the `tensorflow.keras.layers` interface, e.g., ReLU.\n","        batch_norm: True for batch normalization, False otherwise.\n","        name: prefix of the created keras layers.\n","\n","    Output\n","    ----------\n","        X: output tensor.\n","\n","    * The defaut: `kernel_size=3`, is suitable for `pool_size=2`.\n","\n","    '''\n","    # parsers\n","    if unpool is False:\n","        # trans conv configurations\n","        bias_flag = not batch_norm\n","\n","    elif unpool == 'nearest':\n","        # upsample2d configurations\n","        unpool = True\n","        interp = 'nearest'\n","\n","    elif (unpool is True) or (unpool == 'bilinear'):\n","        # upsample2d configurations\n","        unpool = True\n","        interp = 'bilinear'\n","\n","    else:\n","        raise ValueError('Invalid unpool keyword')\n","\n","    if unpool:\n","        X = UpSampling2D(size=(pool_size, pool_size), interpolation=interp, name='{}_unpool'.format(name))(X)\n","    else:\n","        if kernel_size == 'auto':\n","            kernel_size = pool_size\n","\n","        X = Conv2DTranspose(channel, kernel_size, strides=(pool_size, pool_size), \n","                            padding='same', name='{}_trans_conv'.format(name))(X)\n","\n","        # batch normalization\n","        if batch_norm:\n","            X = BatchNormalization(axis=3, name='{}_bn'.format(name))(X)\n","\n","        # activation\n","        if activation is not None:\n","            activation_func = eval(activation)\n","            X = activation_func(name='{}_activation'.format(name))(X)\n","\n","    return X"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T05:18:30.574061Z","iopub.status.busy":"2022-05-29T05:18:30.573733Z","iopub.status.idle":"2022-05-29T05:18:30.584694Z","shell.execute_reply":"2022-05-29T05:18:30.583993Z","shell.execute_reply.started":"2022-05-29T05:18:30.574031Z"},"trusted":true},"outputs":[],"source":["def encode_layer(X, channel, pool_size, pool, kernel_size='auto', \n","                 activation='ReLU', batch_norm=False, name='encode'):\n","    '''\n","    An overall encode layer, based on one of the:\n","    (1) max-pooling, (2) average-pooling, (3) strided conv2d.\n","    \n","    encode_layer(X, channel, pool_size, pool, kernel_size='auto', \n","                 activation='ReLU', batch_norm=False, name='encode')\n","    \n","    Input\n","    ----------\n","        X: input tensor.\n","        pool_size: the encoding factor.\n","        channel: (for strided conv only) number of convolution filters.\n","        pool: True or 'max' for MaxPooling2D.\n","              'ave' for AveragePooling2D.\n","              False for strided conv + batch norm + activation.\n","        kernel_size: size of convolution kernels. \n","                     If kernel_size='auto', then it equals to the `pool_size`.\n","        activation: one of the `tensorflow.keras.layers` interface, e.g., ReLU.\n","        batch_norm: True for batch normalization, False otherwise.\n","        name: prefix of the created keras layers.\n","        \n","    Output\n","    ----------\n","        X: output tensor.\n","        \n","    '''\n","    # parsers\n","    if (pool in [False, True, 'max', 'ave']) is not True:\n","        raise ValueError('Invalid pool keyword')\n","        \n","    # maxpooling2d as default\n","    if pool is True:\n","        pool = 'max'\n","        \n","    elif pool is False:\n","        # stride conv configurations\n","        bias_flag = not batch_norm\n","    \n","    if pool == 'max':\n","        X = MaxPooling2D(pool_size=(pool_size, pool_size), name='{}_maxpool'.format(name))(X)\n","        \n","    elif pool == 'ave':\n","        X = AveragePooling2D(pool_size=(pool_size, pool_size), name='{}_avepool'.format(name))(X)\n","        \n","    else:\n","        if kernel_size == 'auto':\n","            kernel_size = pool_size\n","        \n","        # linear convolution with strides\n","        X = Conv2D(channel, kernel_size, strides=(pool_size, pool_size), \n","                   padding='valid', use_bias=bias_flag, name='{}_stride_conv'.format(name))(X)\n","        \n","        # batch normalization\n","        if batch_norm:\n","            X = BatchNormalization(axis=3, name='{}_bn'.format(name))(X)\n","            \n","        # activation\n","        if activation is not None:\n","            activation_func = eval(activation)\n","            X = activation_func(name='{}_activation'.format(name))(X)\n","            \n","    return X\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T05:18:34.818445Z","iopub.status.busy":"2022-05-29T05:18:34.817776Z","iopub.status.idle":"2022-05-29T05:18:34.826529Z","shell.execute_reply":"2022-05-29T05:18:34.825614Z","shell.execute_reply.started":"2022-05-29T05:18:34.818411Z"},"trusted":true},"outputs":[],"source":["def attention_gate(X, g, channel,  \n","                   activation='ReLU', \n","                   attention='add', name='att'):\n","    '''\n","    Self-attention gate modified from Oktay et al. 2018.\n","    \n","    attention_gate(X, g, channel,  activation='ReLU', attention='add', name='att')\n","    \n","    Input\n","    ----------\n","        X: input tensor, i.e., key and value.\n","        g: gated tensor, i.e., query.\n","        channel: number of intermediate channel.\n","                 Oktay et al. (2018) did not specify (denoted as F_int).\n","                 intermediate channel is expected to be smaller than the input channel.\n","        activation: a nonlinear attnetion activation.\n","                    The `sigma_1` in Oktay et al. 2018. Default is 'ReLU'.\n","        attention: 'add' for additive attention; 'multiply' for multiplicative attention.\n","                   Oktay et al. 2018 applied additive attention.\n","        name: prefix of the created keras layers.\n","        \n","    Output\n","    ----------\n","        X_att: output tensor.\n","    \n","    '''\n","    activation_func = eval(activation)\n","    attention_func = eval(attention)\n","    \n","    # mapping the input tensor to the intermediate channel\n","    theta_att = Conv2D(channel, 1, use_bias=True, name='{}_theta_x'.format(name))(X)\n","    \n","    # mapping the gate tensor\n","    phi_g = Conv2D(channel, 1, use_bias=True, name='{}_phi_g'.format(name))(g)\n","    \n","    # ----- attention learning ----- #\n","    query = attention_func([theta_att, phi_g], name='{}_add'.format(name))\n","    \n","    # nonlinear activation\n","    f = activation_func(name='{}_activation'.format(name))(query)\n","    \n","    # linear transformation\n","    psi_f = Conv2D(1, 1, use_bias=True, name='{}_psi_f'.format(name))(f)\n","    # ------------------------------ #\n","    \n","    # sigmoid activation as attention coefficients\n","    coef_att = Activation('sigmoid', name='{}_sigmoid'.format(name))(psi_f)\n","    \n","    # multiplicative attention masking\n","    X_att = multiply([X, coef_att], name='{}_masking'.format(name))\n","    \n","    return X_att\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T05:18:39.381754Z","iopub.status.busy":"2022-05-29T05:18:39.381507Z","iopub.status.idle":"2022-05-29T05:18:39.389036Z","shell.execute_reply":"2022-05-29T05:18:39.388296Z","shell.execute_reply.started":"2022-05-29T05:18:39.381727Z"},"trusted":true},"outputs":[],"source":["def CONV_stack(X, channel, kernel_size=3, stack_num=2, \n","               dilation_rate=1, activation='ReLU', \n","               batch_norm=False, name='conv_stack'):\n","    '''\n","    Stacked convolutional layers:\n","    (Convolutional layer --> batch normalization --> Activation)*stack_num\n","    \n","    CONV_stack(X, channel, kernel_size=3, stack_num=2, dilation_rate=1, activation='ReLU', \n","               batch_norm=False, name='conv_stack')\n","    \n","    \n","    Input\n","    ----------\n","        X: input tensor.\n","        channel: number of convolution filters.\n","        kernel_size: size of 2-d convolution kernels.\n","        stack_num: number of stacked Conv2D-BN-Activation layers.\n","        dilation_rate: optional dilated convolution kernel.\n","        activation: one of the `tensorflow.keras.layers` interface, e.g., ReLU.\n","        batch_norm: True for batch normalization, False otherwise.\n","        name: prefix of the created keras layers.\n","        \n","    Output\n","    ----------\n","        X: output tensor\n","        \n","    '''\n","    \n","    bias_flag = not batch_norm\n","    \n","    # stacking Convolutional layers\n","    for i in range(stack_num):\n","        \n","        activation_func = eval(activation)\n","        \n","        # linear convolution\n","        X = Conv2D(channel, kernel_size, padding='same', use_bias=bias_flag, \n","                   dilation_rate=dilation_rate, name='{}_{}'.format(name, i))(X)\n","        \n","        # batch normalization\n","        if batch_norm:\n","            X = BatchNormalization(axis=3, name='{}_{}_bn'.format(name, i))(X)\n","        \n","        # activation\n","        activation_func = eval(activation)\n","        X = activation_func(name='{}_{}_activation'.format(name, i))(X)\n","        \n","    return X\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T19:35:18.251023Z","iopub.status.busy":"2022-05-26T19:35:18.250753Z","iopub.status.idle":"2022-05-26T19:35:18.258571Z","shell.execute_reply":"2022-05-26T19:35:18.257583Z","shell.execute_reply.started":"2022-05-26T19:35:18.250991Z"},"trusted":true},"outputs":[],"source":["def Res_CONV_stack(X, X_skip, channel, res_num, activation='ReLU', batch_norm=False, name='res_conv'):\n","    '''\n","    Stacked convolutional layers with residual path.\n","     \n","    Res_CONV_stack(X, X_skip, channel, res_num, activation='ReLU', batch_norm=False, name='res_conv')\n","     \n","    Input\n","    ----------\n","        X: input tensor.\n","        X_skip: the tensor that does go into the residual path \n","                can be a copy of X (e.g., the identity block of ResNet).\n","        channel: number of convolution filters.\n","        res_num: number of convolutional layers within the residual path.\n","        activation: one of the `tensorflow.keras.layers` interface, e.g., 'ReLU'.\n","        batch_norm: True for batch normalization, False otherwise.\n","        name: prefix of the created keras layers.\n","        \n","    Output\n","    ----------\n","        X: output tensor.\n","        \n","    '''  \n","    X = CONV_stack(X, channel, kernel_size=3, stack_num=res_num, dilation_rate=1, \n","                   activation=activation, batch_norm=batch_norm, name=name)\n","\n","    X = add([X_skip, X], name='{}_add'.format(name))\n","    \n","    activation_func = eval(activation)\n","    X = activation_func(name='{}_add_activation'.format(name))(X)\n","    \n","    return X\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T05:18:43.037049Z","iopub.status.busy":"2022-05-29T05:18:43.036402Z","iopub.status.idle":"2022-05-29T05:18:43.048177Z","shell.execute_reply":"2022-05-29T05:18:43.047363Z","shell.execute_reply.started":"2022-05-29T05:18:43.037012Z"},"trusted":true},"outputs":[],"source":["def Sep_CONV_stack(X, channel, kernel_size=3, stack_num=1, dilation_rate=1, activation='ReLU', batch_norm=False, name='sep_conv'):\n","    '''\n","    Depthwise separable convolution with (optional) dilated convolution kernel and batch normalization.\n","    \n","    Sep_CONV_stack(X, channel, kernel_size=3, stack_num=1, dilation_rate=1, activation='ReLU', batch_norm=False, name='sep_conv')\n","    \n","    Input\n","    ----------\n","        X: input tensor.\n","        channel: number of convolution filters.\n","        kernel_size: size of 2-d convolution kernels.\n","        stack_num: number of stacked depthwise-pointwise layers.\n","        dilation_rate: optional dilated convolution kernel.\n","        activation: one of the `tensorflow.keras.layers` interface, e.g., 'ReLU'.\n","        batch_norm: True for batch normalization, False otherwise.\n","        name: prefix of the created keras layers.\n","        \n","    Output\n","    ----------\n","        X: output tensor.\n","    \n","    '''\n","    \n","    activation_func = eval(activation)\n","    bias_flag = not batch_norm\n","    \n","    for i in range(stack_num):\n","        X = DepthwiseConv2D(kernel_size, dilation_rate=dilation_rate, padding='same', \n","                            use_bias=bias_flag, name='{}_{}_depthwise'.format(name, i))(X)\n","        \n","        if batch_norm:\n","            X = BatchNormalization(name='{}_{}_depthwise_BN'.format(name, i))(X)\n","\n","        X = activation_func(name='{}_{}_depthwise_activation'.format(name, i))(X)\n","\n","        X = Conv2D(channel, (1, 1), padding='same', use_bias=bias_flag, name='{}_{}_pointwise'.format(name, i))(X)\n","        \n","        if batch_norm:\n","            X = BatchNormalization(name='{}_{}_pointwise_BN'.format(name, i))(X)\n","\n","        X = activation_func(name='{}_{}_pointwise_activation'.format(name, i))(X)\n","    \n","    return X"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T05:18:46.588236Z","iopub.status.busy":"2022-05-29T05:18:46.587781Z","iopub.status.idle":"2022-05-29T05:18:46.600669Z","shell.execute_reply":"2022-05-29T05:18:46.599944Z","shell.execute_reply.started":"2022-05-29T05:18:46.588197Z"},"trusted":true},"outputs":[],"source":["def ASPP_conv(X, channel, activation='ReLU', batch_norm=True, name='aspp'):\n","    '''\n","    Atrous Spatial Pyramid Pooling (ASPP).\n","    \n","    ASPP_conv(X, channel, activation='ReLU', batch_norm=True, name='aspp')\n","    \n","    ----------\n","    Wang, Y., Liang, B., Ding, M. and Li, J., 2019. Dense semantic labeling \n","    with atrous spatial pyramid pooling and decoder for high-resolution remote \n","    sensing imagery. Remote Sensing, 11(1), p.20.\n","    \n","    Input\n","    ----------\n","        X: input tensor.\n","        channel: number of convolution filters.\n","        activation: one of the `tensorflow.keras.layers` interface, e.g., ReLU.\n","        batch_norm: True for batch normalization, False otherwise.\n","        name: prefix of the created keras layers.\n","        \n","    Output\n","    ----------\n","        X: output tensor.\n","        \n","    * dilation rates are fixed to `[6, 9, 12]`.\n","    '''\n","    \n","    activation_func = eval(activation)\n","    bias_flag = not batch_norm\n","\n","    shape_before = X.get_shape().as_list()\n","    b4 = GlobalAveragePooling2D(name='{}_avepool_b4'.format(name))(X)\n","    \n","    b4 = expand_dims(expand_dims(b4, 1), 1, name='{}_expdim_b4'.format(name))\n","    \n","    b4 = Conv2D(channel, 1, padding='same', use_bias=bias_flag, name='{}_conv_b4'.format(name))(b4)\n","    \n","    if batch_norm:\n","        b4 = BatchNormalization(name='{}_conv_b4_BN'.format(name))(b4)\n","        \n","    b4 = activation_func(name='{}_conv_b4_activation'.format(name))(b4)\n","    \n","    # <----- tensorflow v1 resize.\n","    b4 = Lambda(lambda X: image.resize(X, shape_before[1:3], method='bilinear', align_corners=True), \n","                name='{}_resize_b4'.format(name))(b4)\n","    \n","    b0 = Conv2D(channel, (1, 1), padding='same', use_bias=bias_flag, name='{}_conv_b0'.format(name))(X)\n","\n","    if batch_norm:\n","        b0 = BatchNormalization(name='{}_conv_b0_BN'.format(name))(b0)\n","        \n","    b0 = activation_func(name='{}_conv_b0_activation'.format(name))(b0)\n","    \n","    # dilation rates are fixed to `[6, 9, 12]`.\n","    b_r6 = Sep_CONV_stack(X, channel, kernel_size=3, stack_num=1, activation='ReLU', \n","                        dilation_rate=6, batch_norm=True, name='{}_sepconv_r6'.format(name))\n","    b_r9 = Sep_CONV_stack(X, channel, kernel_size=3, stack_num=1, activation='ReLU', \n","                        dilation_rate=9, batch_norm=True, name='{}_sepconv_r9'.format(name))\n","    b_r12 = Sep_CONV_stack(X, channel, kernel_size=3, stack_num=1, activation='ReLU', \n","                        dilation_rate=12, batch_norm=True, name='{}_sepconv_r12'.format(name))\n","    \n","    return concatenate([b4, b0, b_r6, b_r9, b_r12])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T05:18:50.043373Z","iopub.status.busy":"2022-05-29T05:18:50.043121Z","iopub.status.idle":"2022-05-29T05:18:50.051147Z","shell.execute_reply":"2022-05-29T05:18:50.049182Z","shell.execute_reply.started":"2022-05-29T05:18:50.043345Z"},"trusted":true},"outputs":[],"source":["def CONV_output(X, n_labels, kernel_size=1, activation='Softmax', name='conv_output'):\n","    '''\n","    Convolutional layer with output activation.\n","    \n","    CONV_output(X, n_labels, kernel_size=1, activation='Softmax', name='conv_output')\n","    \n","    Input\n","    ----------\n","        X: input tensor.\n","        n_labels: number of classification label(s).\n","        kernel_size: size of 2-d convolution kernels. Default is 1-by-1.\n","        activation: one of the `tensorflow.keras.layers` or `keras_unet_collection.activations` interface or 'Sigmoid'.\n","                    Default option is 'Softmax'.\n","                    if None is received, then linear activation is applied.\n","        name: prefix of the created keras layers.\n","        \n","    Output\n","    ----------\n","        X: output tensor.\n","        \n","    '''\n","    \n","    X = Conv2D(n_labels, kernel_size, padding='same', use_bias=True, name=name)(X)\n","    \n","    if activation:\n","        \n","        if activation == 'Sigmoid':\n","            X = Activation('sigmoid', name='{}_activation'.format(name))(X)\n","            \n","        else:\n","            activation_func = eval(activation)\n","            X = activation_func(name='{}_activation'.format(name))(X)\n","            \n","    return X"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T05:18:53.746463Z","iopub.status.busy":"2022-05-29T05:18:53.745945Z","iopub.status.idle":"2022-05-29T05:18:53.750596Z","shell.execute_reply":"2022-05-29T05:18:53.749976Z","shell.execute_reply.started":"2022-05-29T05:18:53.746428Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T05:18:55.600703Z","iopub.status.busy":"2022-05-29T05:18:55.60024Z","iopub.status.idle":"2022-05-29T05:18:55.610892Z","shell.execute_reply":"2022-05-29T05:18:55.610213Z","shell.execute_reply.started":"2022-05-29T05:18:55.600663Z"},"trusted":true},"outputs":[],"source":["def RR_CONV(X, channel, kernel_size=3, stack_num=2, recur_num=2, activation='ReLU', batch_norm=False, name='rr'):\n","    '''\n","    Recurrent convolutional layers with skip connection.\n","    \n","    RR_CONV(X, channel, kernel_size=3, stack_num=2, recur_num=2, activation='ReLU', batch_norm=False, name='rr')\n","    \n","    Input\n","    ----------\n","        X: input tensor.\n","        channel: number of convolution filters.\n","        kernel_size: size of 2-d convolution kernels.\n","        stack_num: number of stacked recurrent convolutional layers.\n","        recur_num: number of recurrent iterations.\n","        activation: one of the `tensorflow.keras.layers` or `keras_unet_collection.activations` interfaces, e.g., 'ReLU'.\n","        batch_norm: True for batch normalization, False otherwise.\n","        name: prefix of the created keras layers.\n","        \n","    Output\n","    ----------\n","        X: output tensor.\n","        \n","    '''\n","    \n","    activation_func = eval(activation)\n","    \n","    layer_skip = Conv2D(channel, 1, name='{}_conv'.format(name))(X)\n","    layer_main = layer_skip\n","    \n","    for i in range(stack_num):\n","\n","        layer_res = Conv2D(channel, kernel_size, padding='same', name='{}_conv{}'.format(name, i))(layer_main)\n","        \n","        if batch_norm:\n","            layer_res = BatchNormalization(name='{}_bn{}'.format(name, i))(layer_res)\n","            \n","        layer_res = activation_func(name='{}_activation{}'.format(name, i))(layer_res)\n","            \n","        for j in range(recur_num):\n","            \n","            layer_add = add([layer_res, layer_main], name='{}_add{}_{}'.format(name, i, j))\n","            \n","            layer_res = Conv2D(channel, kernel_size, padding='same', name='{}_conv{}_{}'.format(name, i, j))(layer_add)\n","            \n","            if batch_norm:\n","                layer_res = BatchNormalization(name='{}_bn{}_{}'.format(name, i, j))(layer_res)\n","                \n","            layer_res = activation_func(name='{}_activation{}_{}'.format(name, i, j))(layer_res)\n","            \n","        layer_main = layer_res\n","\n","    out_layer = add([layer_main, layer_skip], name='{}_add{}'.format(name, i))\n","    \n","    return out_layer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T05:18:59.463162Z","iopub.status.busy":"2022-05-29T05:18:59.462887Z","iopub.status.idle":"2022-05-29T05:18:59.470212Z","shell.execute_reply":"2022-05-29T05:18:59.469436Z","shell.execute_reply.started":"2022-05-29T05:18:59.463132Z"},"trusted":true},"outputs":[],"source":["def UNET_RR_left(X, channel, kernel_size=3, \n","                 stack_num=2, recur_num=2, activation='ReLU', \n","                 pool=True, batch_norm=False, name='left0'):\n","    '''\n","    The encoder block of R2U-Net.\n","    \n","    UNET_RR_left(X, channel, kernel_size=3, \n","                 stack_num=2, recur_num=2, activation='ReLU', \n","                 pool=True, batch_norm=False, name='left0')\n","    \n","    Input\n","    ----------\n","        X: input tensor.\n","        channel: number of convolution filters.\n","        kernel_size: size of 2-d convolution kernels.\n","        stack_num: number of stacked recurrent convolutional layers.\n","        recur_num: number of recurrent iterations.\n","        activation: one of the `tensorflow.keras.layers` or `keras_unet_collection.activations` interfaces, e.g., 'ReLU'.\n","        pool: True or 'max' for MaxPooling2D.\n","              'ave' for AveragePooling2D.\n","              False for strided conv + batch norm + activation.\n","        batch_norm: True for batch normalization, False otherwise.\n","        name: prefix of the created keras layers.\n","        \n","    Output\n","    ----------\n","        X: output tensor.\n","    \n","    *downsampling is fixed to 2-by-2, e.g., reducing feature map sizes from 64-by-64 to 32-by-32\n","    '''\n","    pool_size = 2\n","    \n","    # maxpooling layer vs strided convolutional layers\n","    X = encode_layer(X, channel, pool_size, pool, activation=activation, \n","                     batch_norm=batch_norm, name='{}_encode'.format(name))\n","    \n","    # stack linear convolutional layers\n","    X = RR_CONV(X, channel, stack_num=stack_num, recur_num=recur_num, \n","                activation=activation, batch_norm=batch_norm, name=name)    \n","    return X"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T05:19:03.47173Z","iopub.status.busy":"2022-05-29T05:19:03.471038Z","iopub.status.idle":"2022-05-29T05:19:03.482968Z","shell.execute_reply":"2022-05-29T05:19:03.482148Z","shell.execute_reply.started":"2022-05-29T05:19:03.47169Z"},"trusted":true},"outputs":[],"source":["def UNET_RR_right(X, X_list, channel, kernel_size=3, \n","                   stack_num=2, recur_num=2, activation='ReLU',\n","                   unpool=True, batch_norm=False, name='right0'):\n","    '''\n","    The decoder block of R2U-Net.\n","    \n","    UNET_RR_right(X, X_list, channel, kernel_size=3, \n","                  stack_num=2, recur_num=2, activation='ReLU',\n","                  unpool=True, batch_norm=False, name='right0')\n","    \n","    Input\n","    ----------\n","        X: input tensor.\n","        X_list: a list of other tensors that connected to the input tensor.\n","        channel: number of convolution filters.\n","        kernel_size: size of 2-d convolution kernels.\n","        stack_num: number of stacked recurrent convolutional layers.\n","        recur_num: number of recurrent iterations.\n","        activation: one of the `tensorflow.keras.layers` or `keras_unet_collection.activations` interfaces, e.g., 'ReLU'.\n","        unpool: True or 'bilinear' for Upsampling2D with bilinear interpolation.\n","                'nearest' for Upsampling2D with nearest interpolation.\n","                False for Conv2DTranspose + batch norm + activation.\n","        batch_norm: True for batch normalization, False otherwise.\n","        name: prefix of the created keras layers.\n","        \n","    Output\n","    ----------\n","        X: output tensor\n","    \n","    '''\n","    \n","    pool_size = 2\n","    \n","    X = decode_layer(X, channel, pool_size, unpool, \n","                     activation=activation, batch_norm=batch_norm, name='{}_decode'.format(name))\n","    \n","    # linear convolutional layers before concatenation\n","    X = CONV_stack(X, channel, kernel_size, stack_num=1, activation=activation, \n","                   batch_norm=batch_norm, name='{}_conv_before_concat'.format(name))\n","    \n","    # Tensor concatenation\n","    H = concatenate([X,]+X_list, axis=-1, name='{}_concat'.format(name))\n","    \n","    # stacked linear convolutional layers after concatenation\n","    H = RR_CONV(H, channel, stack_num=stack_num, recur_num=recur_num, \n","                      activation=activation, batch_norm=batch_norm, name=name)\n","    \n","    return H"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T05:19:06.874084Z","iopub.status.busy":"2022-05-29T05:19:06.873649Z","iopub.status.idle":"2022-05-29T05:19:06.884315Z","shell.execute_reply":"2022-05-29T05:19:06.883576Z","shell.execute_reply.started":"2022-05-29T05:19:06.874048Z"},"trusted":true},"outputs":[],"source":["def r2_unet_2d_base(input_tensor, filter_num, stack_num_down=2, stack_num_up=2, recur_num=2,\n","                    activation='ReLU', batch_norm=False, pool=True, unpool=True, name='res_unet'):\n","    \n","    '''\n","    The base of Recurrent Residual (R2) U-Net.\n","    \n","    r2_unet_2d_base(input_tensor, filter_num, stack_num_down=2, stack_num_up=2, recur_num=2,\n","                    activation='ReLU', batch_norm=False, pool=True, unpool=True, name='res_unet')\n","    \n","    ----------\n","    Alom, M.Z., Hasan, M., Yakopcic, C., Taha, T.M. and Asari, V.K., 2018. Recurrent residual convolutional neural network \n","    based on u-net (r2u-net) for medical image segmentation. arXiv preprint arXiv:1802.06955.\n","    \n","    Input\n","    ----------\n","        input_tensor: the input tensor of the base, e.g., `keras.layers.Inpyt((None, None, 3))`.\n","        filter_num: a list that defines the number of filters for each \\\n","                    down- and upsampling levels. e.g., `[64, 128, 256, 512]`.\n","                    The depth is expected as `len(filter_num)`.\n","        stack_num_down: number of stacked recurrent convolutional layers per downsampling level/block.\n","        stack_num_down: number of stacked recurrent convolutional layers per upsampling level/block.\n","        recur_num: number of recurrent iterations.\n","        activation: one of the `tensorflow.keras.layers` or `keras_unet_collection.activations` interfaces, e.g., 'ReLU'.\n","        batch_norm: True for batch normalization.\n","        pool: True or 'max' for MaxPooling2D.\n","              'ave' for AveragePooling2D.\n","              False for strided conv + batch norm + activation.\n","        unpool: True or 'bilinear' for Upsampling2D with bilinear interpolation.\n","                'nearest' for Upsampling2D with nearest interpolation.\n","                False for Conv2DTranspose + batch norm + activation.                 \n","        name: prefix of the created keras layers.\n","        \n","    Output\n","    ----------\n","        X: output tensor.\n","    \n","    '''\n","    \n","    activation_func = eval(activation)\n","\n","    X = input_tensor\n","    X_skip = []\n","    \n","    # downsampling blocks\n","    X = RR_CONV(X, filter_num[0], stack_num=stack_num_down, recur_num=recur_num, \n","                      activation=activation, batch_norm=batch_norm, name='{}_down0'.format(name))\n","    X_skip.append(X)\n","    \n","    for i, f in enumerate(filter_num[1:]):\n","        X = UNET_RR_left(X, f, kernel_size=3, stack_num=stack_num_down, recur_num=recur_num, \n","                          activation=activation, pool=pool, batch_norm=batch_norm, name='{}_down{}'.format(name, i+1))        \n","        X_skip.append(X)\n","    \n","    # upsampling blocks\n","    X_skip = X_skip[:-1][::-1]\n","    for i, f in enumerate(filter_num[:-1][::-1]):\n","        X = UNET_RR_right(X, [X_skip[i],], f, stack_num=stack_num_up, recur_num=recur_num, \n","                           activation=activation, unpool=unpool, batch_norm=batch_norm, name='{}_up{}'.format(name, i+1))\n","    \n","    return X"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T05:19:10.914422Z","iopub.status.busy":"2022-05-29T05:19:10.913999Z","iopub.status.idle":"2022-05-29T05:19:10.923604Z","shell.execute_reply":"2022-05-29T05:19:10.922612Z","shell.execute_reply.started":"2022-05-29T05:19:10.914383Z"},"trusted":true},"outputs":[],"source":["def r2_unet_2d(input_size, filter_num, n_labels, \n","               stack_num_down=2, stack_num_up=2, recur_num=2,\n","               activation='ReLU', output_activation='Softmax', \n","               batch_norm=False, pool=True, unpool=True, name='r2_unet'):\n","    \n","    '''\n","    Recurrent Residual (R2) U-Net\n","    \n","    r2_unet_2d(input_size, filter_num, n_labels, \n","               stack_num_down=2, stack_num_up=2, recur_num=2,\n","               activation='ReLU', output_activation='Softmax', \n","               batch_norm=False, pool=True, unpool=True, name='r2_unet')\n","    \n","    ----------\n","    Alom, M.Z., Hasan, M., Yakopcic, C., Taha, T.M. and Asari, V.K., 2018. Recurrent residual convolutional neural network \n","    based on u-net (r2u-net) for medical image segmentation. arXiv preprint arXiv:1802.06955.\n","    \n","    Input\n","    ----------\n","        input_size: the size/shape of network input, e.g., `(128, 128, 3)`.\n","        filter_num: a list that defines the number of filters for each \\\n","                    down- and upsampling levels. e.g., `[64, 128, 256, 512]`.\n","                    The depth is expected as `len(filter_num)`.\n","        n_labels: number of output labels.\n","        stack_num_down: number of stacked recurrent convolutional layers per downsampling level/block.\n","        stack_num_down: number of stacked recurrent convolutional layers per upsampling level/block.\n","        recur_num: number of recurrent iterations.\n","        activation: one of the `tensorflow.keras.layers` or `keras_unet_collection.activations` interfaces, e.g., 'ReLU'.\n","        output_activation: one of the `tensorflow.keras.layers` or `keras_unet_collection.activations` interface or 'Sigmoid'.\n","                           Default option is 'Softmax'.\n","                           if None is received, then linear activation is applied.     \n","        batch_norm: True for batch normalization.\n","        pool: True or 'max' for MaxPooling2D.\n","              'ave' for AveragePooling2D.\n","              False for strided conv + batch norm + activation.\n","        unpool: True or 'bilinear' for Upsampling2D with bilinear interpolation.\n","                'nearest' for Upsampling2D with nearest interpolation.\n","                False for Conv2DTranspose + batch norm + activation.                  \n","        name: prefix of the created keras layers.\n","        \n","    Output\n","    ----------\n","        model: a keras model.\n","    \n","    '''\n","    \n","    activation_func = eval(activation)\n","\n","    IN = Input(input_size, name='{}_input'.format(name))\n","\n","    # base\n","    X = r2_unet_2d_base(IN, filter_num, \n","                        stack_num_down=stack_num_down, stack_num_up=stack_num_up, recur_num=recur_num,\n","                        activation=activation, batch_norm=batch_norm, pool=pool, unpool=unpool, name=name)\n","    # output layer\n","    OUT = CONV_output(X, n_labels, kernel_size=1, activation=output_activation, name='{}_output'.format(name))\n","    \n","    # functional API model\n","    model = Model(inputs=[IN], outputs=[OUT], name='{}_model'.format(name))\n","    \n","    return model "]},{"cell_type":"markdown","metadata":{},"source":["**U-Net Backbone ResNet 50**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T20:03:43.598538Z","iopub.status.busy":"2022-05-26T20:03:43.598088Z","iopub.status.idle":"2022-05-26T20:03:43.615847Z","shell.execute_reply":"2022-05-26T20:03:43.614897Z","shell.execute_reply.started":"2022-05-26T20:03:43.598501Z"},"trusted":true},"outputs":[],"source":["\n","\n","def conv_block(input, num_filters):\n","    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","\n","    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","\n","    return x\n","\n","def decoder_block(input, skip_features, num_filters):\n","    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n","    x = Concatenate()([x, skip_features])\n","    x = conv_block(x, num_filters)\n","    return x\n","\n","def build_resnet50_unet(input_shape):\n","    \"\"\" Input \"\"\"\n","    inputs = Input(input_shape)\n","\n","    \"\"\" Pre-trained ResNet50 Model \"\"\"\n","    resnet50 = ResNet50(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n","\n","    \"\"\" Encoder \"\"\"\n","    s1 = resnet50.get_layer(\"input_1\").output           ## (512 x 512)\n","    s2 = resnet50.get_layer(\"conv1_relu\").output        ## (256 x 256)\n","    s3 = resnet50.get_layer(\"conv2_block3_out\").output  ## (128 x 128)\n","    s4 = resnet50.get_layer(\"conv3_block4_out\").output  ## (64 x 64)\n","\n","    \"\"\" Bridge \"\"\"\n","    b1 = resnet50.get_layer(\"conv4_block6_out\").output  ## (32 x 32)\n","\n","    \"\"\" Decoder \"\"\"\n","    d1 = decoder_block(b1, s4, 512)                     ## (64 x 64)\n","    d2 = decoder_block(d1, s3, 256)                     ## (128 x 128)\n","    d3 = decoder_block(d2, s2, 128)                     ## (256 x 256)\n","    d4 = decoder_block(d3, s1, 64)                      ## (512 x 512)\n","\n","    \"\"\" Output \"\"\"\n","    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n","\n","    model = Model(inputs, outputs, name=\"ResNet50_U-Net\")\n","    return model\n","\n","def build_resnet50_unet1(input_shape):\n","    \"\"\" Input \"\"\"\n","    inputs = Input(input_shape)\n","\n","    \"\"\" Pre-trained ResNet50 Model \"\"\"\n","    resnet50 = ResNet50(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n","\n","    \"\"\" Encoder \"\"\"\n","    s1 = resnet50.get_layer(\"input_2\").output           ## (512 x 512)\n","    s2 = resnet50.get_layer(\"conv1_relu\").output        ## (256 x 256)\n","    s3 = resnet50.get_layer(\"conv2_block3_out\").output  ## (128 x 128)\n","    s4 = resnet50.get_layer(\"conv3_block4_out\").output  ## (64 x 64)\n","\n","    \"\"\" Bridge \"\"\"\n","    b1 = resnet50.get_layer(\"conv4_block6_out\").output  ## (32 x 32)\n","\n","    \"\"\" Decoder \"\"\"\n","    d1 = decoder_block(b1, s4, 512)                     ## (64 x 64)\n","    d2 = decoder_block(d1, s3, 256)                     ## (128 x 128)\n","    d3 = decoder_block(d2, s2, 128)                     ## (256 x 256)\n","    d4 = decoder_block(d3, s1, 64)                      ## (512 x 512)\n","\n","    \"\"\" Output \"\"\"\n","    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n","\n","    model = Model(inputs, outputs, name=\"ResNet50_U-Net\")\n","    return model"]},{"cell_type":"markdown","metadata":{},"source":["**U-net**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-31T12:16:58.975716Z","iopub.status.busy":"2022-03-31T12:16:58.975189Z","iopub.status.idle":"2022-03-31T12:16:58.992691Z","shell.execute_reply":"2022-03-31T12:16:58.99205Z","shell.execute_reply.started":"2022-03-31T12:16:58.97568Z"},"trusted":true},"outputs":[],"source":["def unet(input_size=(256,256,1)):\n","    inputs = Input(input_size)\n","    \n","    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n","    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","\n","    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n","    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","\n","    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n","    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","\n","    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n","    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n","\n","    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n","    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n","\n","    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n","    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n","    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n","\n","    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n","    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n","    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n","\n","    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n","    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n","    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n","\n","    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n","    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n","    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n","\n","    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n","\n","    return Model(inputs=[inputs], outputs=[conv10])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T05:19:35.270286Z","iopub.status.busy":"2022-05-29T05:19:35.270032Z","iopub.status.idle":"2022-05-29T05:19:39.513132Z","shell.execute_reply":"2022-05-29T05:19:39.512418Z","shell.execute_reply.started":"2022-05-29T05:19:35.27026Z"},"trusted":true},"outputs":[],"source":["model = r2_unet_2d(input_size = (512,512,1), filter_num = [32, 64, 128, 256, 512], n_labels = 1, \n","               stack_num_down=2, stack_num_up=2, recur_num=3,\n","               activation='ReLU', output_activation='Sigmoid', \n","               batch_norm=True, pool=True, unpool=True, name='r2_unet')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-24T19:33:04.079642Z","iopub.status.busy":"2022-05-24T19:33:04.078883Z","iopub.status.idle":"2022-05-24T19:33:04.218185Z","shell.execute_reply":"2022-05-24T19:33:04.213332Z","shell.execute_reply.started":"2022-05-24T19:33:04.079602Z"},"trusted":true},"outputs":[],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["# Image Datagenerator"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T05:19:56.096187Z","iopub.status.busy":"2022-05-29T05:19:56.095748Z","iopub.status.idle":"2022-05-29T05:19:56.10936Z","shell.execute_reply":"2022-05-29T05:19:56.108601Z","shell.execute_reply.started":"2022-05-29T05:19:56.096151Z"},"trusted":true},"outputs":[],"source":["def adjustData(img,mask,flag_multi_class,num_class):\n","    if(flag_multi_class):\n","        img = img / 255\n","        mask = mask[:,:,:,0] if(len(mask.shape) == 4) else mask[:,:,0]\n","        new_mask = np.zeros(mask.shape + (num_class,))\n","        for i in range(num_class):\n","            #for one pixel in the image, find the class in mask and convert it into one-hot vector\n","            #index = np.where(mask == i)\n","            #index_mask = (index[0],index[1],index[2],np.zeros(len(index[0]),dtype = np.int64) + i) if (len(mask.shape) == 4) else (index[0],index[1],np.zeros(len(index[0]),dtype = np.int64) + i)\n","            #new_mask[index_mask] = 1\n","            new_mask[mask == i,i] = 1\n","        new_mask = np.reshape(new_mask,(new_mask.shape[0],new_mask.shape[1]*new_mask.shape[2],new_mask.shape[3])) if flag_multi_class else np.reshape(new_mask,(new_mask.shape[0]*new_mask.shape[1],new_mask.shape[2]))\n","        mask = new_mask\n","    elif(np.max(img) > 1):\n","        img = img / 255\n","        mask = mask /255\n","        mask[mask > 0.5] = 1\n","        mask[mask <= 0.5] = 0\n","    return (img,mask)\n","def trainGenerator(batch_size,train_path,image_folder,\n","                   mask_folder,\n","                   aug_dict,\n","                   image_color_mode = \"grayscale\",\n","                   mask_color_mode = \"grayscale\",\n","                   image_save_prefix  = \"image\",\n","                   mask_save_prefix  = \"mask\",\n","                   flag_multi_class = False,\n","                   num_class = 2,\n","                   save_to_dir = None,\n","                   target_size = (256,256),\n","                   seed = 1,\n","                   subset = 'training'):\n","    '''\n","    can generate image and mask at the same time\n","    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n","    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n","    '''\n","    image_datagen = ImageDataGenerator(**aug_dict)\n","    mask_datagen = ImageDataGenerator(**aug_dict)\n","    image_generator = image_datagen.flow_from_directory(\n","        train_path,\n","        classes = [image_folder],\n","        class_mode = None,\n","        color_mode = image_color_mode,\n","        target_size = target_size,\n","        batch_size = batch_size,\n","        save_to_dir = save_to_dir,\n","        save_prefix  = image_save_prefix,\n","        seed = seed,\n","        subset = subset)\n","    mask_generator = mask_datagen.flow_from_directory(\n","        train_path,\n","        classes = [mask_folder],\n","        class_mode = None,\n","        color_mode = mask_color_mode,\n","        target_size = target_size,\n","        batch_size = batch_size,\n","        save_to_dir = save_to_dir,\n","        save_prefix  = mask_save_prefix,\n","        seed = seed,\n","        subset = subset)\n","    train_generator = zip(image_generator, mask_generator)\n","    for (img,mask) in train_generator:\n","        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n","        yield (img,mask)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T05:20:03.407009Z","iopub.status.busy":"2022-05-29T05:20:03.406457Z","iopub.status.idle":"2022-05-29T05:20:03.412895Z","shell.execute_reply":"2022-05-29T05:20:03.411829Z","shell.execute_reply.started":"2022-05-29T05:20:03.406974Z"},"trusted":true},"outputs":[],"source":["def display(display_list):\n","    plt.figure(figsize=(15,15))\n","    \n","    title = ['Input Image', 'True Mask', 'Predicted Mask']\n","    \n","    for i in range(len(display_list)):\n","        plt.subplot(1, len(display_list), i+1)\n","        plt.title(title[i])\n","        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]), cmap='gray')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T05:20:08.369867Z","iopub.status.busy":"2022-05-29T05:20:08.3696Z","iopub.status.idle":"2022-05-29T05:20:08.375359Z","shell.execute_reply":"2022-05-29T05:20:08.374657Z","shell.execute_reply.started":"2022-05-29T05:20:08.369838Z"},"trusted":true},"outputs":[],"source":["def show_dataset(datagen, num=1):\n","    for i in range(0,num):\n","        image,mask = next(datagen)\n","        display([image[0], mask[0]])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-24T19:34:12.561023Z","iopub.status.busy":"2022-05-24T19:34:12.560706Z","iopub.status.idle":"2022-05-24T19:38:19.938863Z","shell.execute_reply":"2022-05-24T19:38:19.938085Z","shell.execute_reply.started":"2022-05-24T19:34:12.560989Z"},"trusted":true},"outputs":[],"source":["#Create paths for tumor segmentation\n","tumor_seg = './train_tumor_seg'\n","os.mkdir(tumor_seg)\n","train_tumor_seg = os.path.join(tumor_seg, 'train')\n","os.mkdir(train_tumor_seg)\n","valid_tumor_seg = os.path.join(tumor_seg, 'valid')\n","os.mkdir(valid_tumor_seg)\n","train_CT_images = os.path.join(train_tumor_seg, 'CT_images')\n","os.mkdir(train_CT_images)\n","train_ct_images = os.path.join(train_CT_images, 'ct_images')\n","os.mkdir(train_ct_images)\n","train_Tumor_masks = os.path.join(train_tumor_seg, 'Tumor_masks')\n","os.mkdir(train_Tumor_masks)\n","train_tumor_masks = os.path.join(train_Tumor_masks, 'tumor_masks')\n","os.mkdir(train_tumor_masks)\n","valid_CT_images = os.path.join(valid_tumor_seg, 'CT_images')\n","os.mkdir(valid_CT_images)\n","valid_ct_images = os.path.join(valid_CT_images, 'ct_images')\n","os.mkdir(valid_ct_images)\n","valid_Tumor_masks = os.path.join(valid_tumor_seg, 'Tumor_masks')\n","os.mkdir(valid_Tumor_masks)\n","valid_tumor_masks = os.path.join(valid_Tumor_masks, 'tumor_masks')\n","os.mkdir(valid_tumor_masks)\n","\n","\n","train_path = '../input/cropped-lits17/liver-crops-train/liver-crops-train'\n","valid_path = '../input/cropped-lits17/liver-crops-valid/liver-crops-valid'\n","train_ct_path = os.path.join(train_path, 'ct')\n","valid_ct_path = os.path.join(valid_path, 'ct')\n","train_tumor_path = os.path.join(train_path, 'tumor_seg')\n","valid_tumor_path = os.path.join(valid_path, 'tumor_seg')\n","\n","\n","train_filenames = os.listdir(train_tumor_path)\n","train_tumor_slices = []\n","train_non_tumor_slices = []\n","for filename in train_filenames:\n","    slice = cv2.imread(os.path.join(train_tumor_path, filename), cv2.IMREAD_GRAYSCALE)\n","    if slice.sum() == 0:\n","        train_non_tumor_slices.append(filename)\n","    else:\n","        train_tumor_slices.append(filename)\n","\n","print('Number of tumor slices:', len(train_tumor_slices))\n","print('Number of non tumor slices:', len(train_non_tumor_slices))\n","\n","valid_filenames = os.listdir(valid_tumor_path)\n","valid_tumor_slices = []\n","valid_non_tumor_slices = []\n","for filename in valid_filenames:\n","    slice = cv2.imread(os.path.join(valid_tumor_path, filename), cv2.IMREAD_GRAYSCALE)\n","    if slice.sum() == 0:\n","        valid_non_tumor_slices.append(filename)\n","    else:\n","        valid_tumor_slices.append(filename)\n","\n","print('Number of tumor slices:', len(valid_tumor_slices))\n","print('Number of non tumor slices:', len(valid_non_tumor_slices))\n","\n","\n","if len(train_tumor_slices) <= len(train_non_tumor_slices):\n","  random.shuffle(train_non_tumor_slices)\n","  train_non_tumor_slices = train_non_tumor_slices[:len(train_tumor_slices)]\n","else:\n","  random.shuffle(train_tumor_slices)\n","  train_tumor_slices = train_tumor_slices[:len(train_non_tumor_slices)]\n","train_tumor_list = train_tumor_slices + train_non_tumor_slices\n","\n","if len(valid_tumor_slices) <= len(valid_non_tumor_slices):\n","  random.shuffle(valid_non_tumor_slices)\n","  valid_non_tumor_slices = valid_non_tumor_slices[:len(valid_tumor_slices)]\n","else:\n","  random.shuffle(valid_tumor_slices)\n","  valid_tumor_slices = valid_tumor_slices[:len(valid_non_tumor_slices)]\n","valid_tumor_list = valid_tumor_slices + valid_non_tumor_slices\n","\n","print(len(train_tumor_list), len(valid_tumor_list))\n","\n","for filename in train_tumor_list:\n","    image = cv2.imread(os.path.join(train_ct_path, filename.replace('segmentation', 'volume')))\n","\n","    tumor_mask = cv2.imread(os.path.join(train_tumor_path, filename), cv2.IMREAD_GRAYSCALE)\n","    \n","    cv2.imwrite(os.path.join(train_ct_images, filename.replace('segmentation', 'volume')), image)\n","    cv2.imwrite(os.path.join(train_tumor_masks, filename), tumor_mask)\n","\n","for filename in valid_tumor_list:\n","    image = cv2.imread(os.path.join(valid_ct_path, filename.replace('segmentation', 'volume')))\n","\n","    tumor_mask = cv2.imread(os.path.join(valid_tumor_path, filename), cv2.IMREAD_GRAYSCALE)\n","    \n","    cv2.imwrite(os.path.join(valid_ct_images, filename.replace('segmentation', 'volume')), image)\n","    cv2.imwrite(os.path.join(valid_tumor_masks, filename), tumor_mask)\n","\n","data_gen_args = dict(rotation_range=0.2,\n","                    width_shift_range=0.1,\n","                    height_shift_range=0.1,\n","                    shear_range=0.05,\n","                    zoom_range=0.1,\n","                    horizontal_flip=True,\n","                    vertical_flip=True,\n","                    fill_mode='nearest',\n","                    validation_split=0)\n","\n","\n","train_generator = trainGenerator(4,'./train_tumor_seg/train','CT_images','Tumor_masks',data_gen_args,save_to_dir = None,\n","                                target_size = (512, 512))\n","valid_generator = trainGenerator(4,'./train_tumor_seg/valid','CT_images','Tumor_masks',data_gen_args,save_to_dir = None,\n","                                target_size = (512, 512))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-24T19:38:45.568647Z","iopub.status.busy":"2022-05-24T19:38:45.56837Z","iopub.status.idle":"2022-05-24T19:38:49.227186Z","shell.execute_reply":"2022-05-24T19:38:49.226409Z","shell.execute_reply.started":"2022-05-24T19:38:45.568619Z"},"trusted":true},"outputs":[],"source":["show_dataset(train_generator, 5)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-24T19:38:55.122634Z","iopub.status.busy":"2022-05-24T19:38:55.122338Z","iopub.status.idle":"2022-05-24T19:38:58.506089Z","shell.execute_reply":"2022-05-24T19:38:58.505431Z","shell.execute_reply.started":"2022-05-24T19:38:55.122602Z"},"trusted":true},"outputs":[],"source":["show_dataset(valid_generator, 5)"]},{"cell_type":"markdown","metadata":{},"source":["# Trainning"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T05:20:32.358921Z","iopub.status.busy":"2022-05-29T05:20:32.358643Z","iopub.status.idle":"2022-05-29T05:20:32.36851Z","shell.execute_reply":"2022-05-29T05:20:32.367815Z","shell.execute_reply.started":"2022-05-29T05:20:32.35889Z"},"trusted":true},"outputs":[],"source":["def dice_coef(y_true, y_pred):\n","    y_true_f = keras.flatten(y_true)\n","    y_pred_f = keras.flatten(y_pred)\n","    intersection = keras.sum(y_true_f * y_pred_f)\n","    return (2. * intersection + 1) / (keras.sum(y_true_f) + keras.sum(y_pred_f) + 1)\n","\n","def dice_coef_loss(y_true, y_pred):\n","    return -dice_coef(y_true, y_pred)\n","def jacard_coef(y_true, y_pred):\n","    y_true_f = keras.flatten(y_true)\n","    y_pred_f = keras.flatten(y_pred)\n","    intersection = keras.sum(y_true_f * y_pred_f)\n","    return (intersection + 1.0) / (keras.sum(y_true_f) + keras.sum(y_pred_f) - intersection + 1.0)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T05:20:37.127725Z","iopub.status.busy":"2022-05-29T05:20:37.127236Z","iopub.status.idle":"2022-05-29T05:20:37.133522Z","shell.execute_reply":"2022-05-29T05:20:37.13281Z","shell.execute_reply.started":"2022-05-29T05:20:37.12769Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n","weight_path=\"{}_weights.best.hdf5\".format('tumor_LITS17')\n","\n","checkpoint = ModelCheckpoint(weight_path, monitor='val_dice_coef', verbose=1, \n","                             save_best_only=True, mode='max', save_weights_only = True)\n","\n","# reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, \n","#                                    patience=3, \n","#                                    verbose=1, mode='min', epsilon=0.0001, cooldown=2, min_lr=1e-6)\n","early = EarlyStopping(monitor=\"val_dice_coef\", \n","                      mode=\"max\", \n","                      patience=15) # probably needs to be more patient, but kaggle time is limited\n","callbacks_list = [checkpoint, early]\n","# callbacks_list = [checkpoint]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-24T19:43:16.737462Z","iopub.status.busy":"2022-05-24T19:43:16.737203Z","iopub.status.idle":"2022-05-24T19:43:16.741936Z","shell.execute_reply":"2022-05-24T19:43:16.741009Z","shell.execute_reply.started":"2022-05-24T19:43:16.737435Z"},"trusted":true},"outputs":[],"source":["num_train = 9200\n","num_valid = 5146\n","\n","train_batchsize = 4\n","valid_batchsize = 4\n","\n","Step_train = num_train // train_batchsize\n","Step_valid = num_valid // valid_batchsize\n","epochs = 20"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T05:20:46.7127Z","iopub.status.busy":"2022-05-29T05:20:46.712444Z","iopub.status.idle":"2022-05-29T05:20:46.716918Z","shell.execute_reply":"2022-05-29T05:20:46.715979Z","shell.execute_reply.started":"2022-05-29T05:20:46.712672Z"},"trusted":true},"outputs":[],"source":["optimizer = Adam(learning_rate=1e-5)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T05:20:48.266088Z","iopub.status.busy":"2022-05-29T05:20:48.265359Z","iopub.status.idle":"2022-05-29T05:20:48.2939Z","shell.execute_reply":"2022-05-29T05:20:48.293215Z","shell.execute_reply.started":"2022-05-29T05:20:48.266033Z"},"trusted":true},"outputs":[],"source":["model.compile(optimizer=optimizer, loss=dice_coef_loss,\n","                  metrics=[dice_coef, jacard_coef])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-24T19:43:29.652334Z","iopub.status.busy":"2022-05-24T19:43:29.651789Z","iopub.status.idle":"2022-05-24T19:44:52.047017Z","shell.execute_reply":"2022-05-24T19:44:52.046119Z","shell.execute_reply.started":"2022-05-24T19:43:29.652297Z"},"trusted":true},"outputs":[],"source":["history = model.fit(\n","    train_generator,\n","    steps_per_epoch=Step_train,\n","    epochs=epochs,\n","    validation_data=valid_generator,\n","    validation_steps=Step_valid,\n","    verbose=1,\n","    callbacks=callbacks_list\n",")"]},{"cell_type":"markdown","metadata":{},"source":["# **Testing**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T05:27:43.14995Z","iopub.status.busy":"2022-05-29T05:27:43.149579Z","iopub.status.idle":"2022-05-29T05:27:45.025399Z","shell.execute_reply":"2022-05-29T05:27:45.024627Z","shell.execute_reply.started":"2022-05-29T05:27:43.149918Z"},"trusted":true},"outputs":[],"source":["model.load_weights('../input/saved-models/tumor_LITS17_weights.best (2).hdf5')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T05:27:46.862175Z","iopub.status.busy":"2022-05-29T05:27:46.861692Z","iopub.status.idle":"2022-05-29T05:27:46.869119Z","shell.execute_reply":"2022-05-29T05:27:46.868124Z","shell.execute_reply.started":"2022-05-29T05:27:46.862142Z"},"trusted":true},"outputs":[],"source":["aug_dict = dict(featurewise_center=False,\n","    samplewise_center=False,\n","    featurewise_std_normalization=False,\n","    samplewise_std_normalization=False,\n","    zca_whitening=False,\n","    zca_epsilon=1e-06,\n","    rotation_range=0,\n","    width_shift_range=0.0,\n","    height_shift_range=0.0,\n","    brightness_range=None,\n","    shear_range=0.0,\n","    zoom_range=0.0,\n","    channel_shift_range=0.0,\n","    fill_mode='nearest',\n","    cval=0.0,\n","    horizontal_flip=False,\n","    vertical_flip=False,\n","    rescale=None,\n","    preprocessing_function=None,\n","    data_format=None,\n","    validation_split=0.0,\n","    dtype=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T05:27:51.196627Z","iopub.status.busy":"2022-05-29T05:27:51.196375Z","iopub.status.idle":"2022-05-29T05:27:51.203217Z","shell.execute_reply":"2022-05-29T05:27:51.202471Z","shell.execute_reply.started":"2022-05-29T05:27:51.196599Z"},"trusted":true},"outputs":[],"source":["test_generator = trainGenerator(4,\"../input/cropped-lits17/liver-crops-test/liver-crops-test\",'ct','tumor_seg',aug_dict=aug_dict,save_to_dir = None,\n","                                target_size = (512,512))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T19:44:31.513098Z","iopub.status.busy":"2022-05-26T19:44:31.512563Z","iopub.status.idle":"2022-05-26T19:44:36.408297Z","shell.execute_reply":"2022-05-26T19:44:36.407556Z","shell.execute_reply.started":"2022-05-26T19:44:31.513059Z"},"trusted":true},"outputs":[],"source":["show_dataset(test_generator, num=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T05:27:56.250377Z","iopub.status.busy":"2022-05-29T05:27:56.249705Z","iopub.status.idle":"2022-05-29T05:27:56.254269Z","shell.execute_reply":"2022-05-29T05:27:56.253332Z","shell.execute_reply.started":"2022-05-29T05:27:56.250342Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.callbacks import Callback"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T05:27:57.961899Z","iopub.status.busy":"2022-05-29T05:27:57.961629Z","iopub.status.idle":"2022-05-29T05:27:57.968335Z","shell.execute_reply":"2022-05-29T05:27:57.967662Z","shell.execute_reply.started":"2022-05-29T05:27:57.96187Z"},"trusted":true},"outputs":[],"source":["Dice_list = []\n","IoU_list = []\n","class LossAndErrorPrintingCallback(Callback):\n","    def on_train_batch_end(self, batch, logs=None):\n","        print(\n","            \"Up to batch {}, the average loss is {:7.5f}.\".format(batch, logs[\"loss\"])\n","        )\n","\n","    def on_test_batch_end(self, batch, logs=None):\n","        print(\n","            \"Up to batch {}, the average loss is {:7.5f}\".format(batch, logs[\"loss\"])\n","        )\n","        Dice_list.append(logs[\"dice_coef\"])\n","        IoU_list.append(logs[\"jacard_coef\"])\n","\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        print(\n","            \"The average loss for epoch {} is {:7.5f} \"\n","            \"and mean absolute error is {:7.2f}.\".format(\n","                epoch, logs[\"loss\"], logs[\"mean_absolute_error\"]\n","            )\n","        )\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T05:28:01.682056Z","iopub.status.busy":"2022-05-29T05:28:01.681501Z","iopub.status.idle":"2022-05-29T05:28:01.686817Z","shell.execute_reply":"2022-05-29T05:28:01.686028Z","shell.execute_reply.started":"2022-05-29T05:28:01.682017Z"},"trusted":true},"outputs":[],"source":["num_test = 3171 \n","test_batchsize = 1\n","Step_test = num_test // test_batchsize\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T05:28:04.509928Z","iopub.status.busy":"2022-05-29T05:28:04.509327Z","iopub.status.idle":"2022-05-29T05:38:56.403396Z","shell.execute_reply":"2022-05-29T05:38:56.402642Z","shell.execute_reply.started":"2022-05-29T05:28:04.509887Z"},"trusted":true},"outputs":[],"source":["model.evaluate(\n","    test_generator,\n","    batch_size=1,\n","    steps=Step_test,\n","    verbose=1,\n","    callbacks=[LossAndErrorPrintingCallback()],\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T05:41:55.824461Z","iopub.status.busy":"2022-05-29T05:41:55.824199Z","iopub.status.idle":"2022-05-29T05:41:55.839152Z","shell.execute_reply":"2022-05-29T05:41:55.838479Z","shell.execute_reply.started":"2022-05-29T05:41:55.824431Z"},"trusted":true},"outputs":[],"source":["from statistics import mean\n","print(\"Dice:{}, IoU: {}\".format(mean(Dice_list), mean(IoU_list)))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
